{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a003aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df51b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Second Book of THE HUNGER GAMES     New York Times Bestsel ling Author   SUZHNNE  COLLINS     PA\n"
     ]
    }
   ],
   "source": [
    "# read a file you have stored locally\n",
    "file = open(\"hunger_games.txt\", 'r').read()\n",
    "\n",
    "# first, remove unwanted new line and tab characters from the text\n",
    "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
    "    file = file.replace(char, \" \")\n",
    "\n",
    "# check\n",
    "print(file[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "089918f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'second', 'book', 'of', 'the', 'hunger', 'games', 'new', 'york', 'times', 'bestsel', 'ling', 'author', 'suzhnne', 'collins', 'parti', '``', 'the', 'spark', \"''\", '2', '|', 'p', 'a', 'g', 'e', 'catching', 'fire', '-', 'suzanne', 'collins', 'i', 'clasp', 'the', 'flask', 'between', 'my', 'hands', 'even', 'though', 'the', 'warmth', 'from', 'the', 'tea', 'has', 'long', 'since', 'leached', 'into', 'the', 'frozen', 'air', '.'], ['my', 'muscles', 'are', 'clenched', 'tight', 'against', 'the', 'cold', '.'], ['if', 'a', 'pack', 'of', 'wild', 'dogs', 'were', 'to', 'appear', 'at', 'this', 'moment', ',', 'the', 'odds', 'of', 'scaling', 'a', 'tree', 'before', 'they', 'attacked', 'are', 'not', 'in', 'my', 'favor', '.'], ['i', 'should', 'get', 'up', ',', 'move', 'around', ',', 'and', 'work', 'the', 'stiffness', 'from', 'my', 'limbs', '.'], ['but', 'instead', 'i', 'sit', ',', 'as', 'motionless', 'as', 'the', 'rock', 'beneath', 'me', ',', 'while', 'the', 'dawn', 'begins', 'to', 'lighten', 'the', 'woods', '.'], ['i', 'ca', \"n't\", 'fight', 'the', 'sun', '.'], ['i', 'can', 'only', 'watch', 'helplessly', 'as', 'it', 'drags', 'me', 'into', 'a', 'day', 'that', 'i', \"'ve\", 'been', 'dreading', 'for', 'months', '.'], ['by', 'noon', 'they', 'will', 'all', 'be', 'at', 'my', 'new', 'house', 'in', 'the', 'victor', \"'s\", 'village', '.'], ['the', 'reporters', ',', 'the', 'camera', 'crews', ',', 'even', 'effie', 'trinket', ',', 'my', 'old', 'escort', ',', 'will', 'have', 'made', 'their', 'way', 'to', 'district', '12', 'from', 'the', 'capitol', '.'], ['i', 'wonder', 'if', 'effie', 'will', 'still', 'be', 'wearing', 'that', 'silly', 'pink', 'wig', ',', 'or', 'if', 'she', \"'ll\", 'be', 'sporting', 'some', 'other', 'unnatural', 'color', 'especially', 'for', 'the', 'victory', 'tour', '.'], ['there', 'will', 'be', 'others', 'waiting', ',', 'too', '.'], ['a', 'staff', 'to', 'cater', 'to', 'my', 'every', 'need', 'on', 'the', 'long', 'train', 'trip', '.'], ['a', 'prep', 'team', 'to', 'beautify', 'me', 'for', 'public', 'appearances', '.'], ['my', 'stylist', 'and', 'friend', ',', 'cinna', ',', 'who', 'designed', 'the', 'gorgeous', 'outfits', 'that', 'first', 'made', 'the', 'audience', 'take', 'notice', 'of', 'me', 'in', 'the', 'hunger', 'games', '.'], ['if', 'it', 'were', 'up', 'to', 'me', ',', 'i', 'would', 'try', 'to', 'forget', 'the', 'hunger', 'games', 'entirely', '.'], ['never', 'speak', 'of', 'them', '.'], ['pretend', 'they', 'were', 'nothing', 'but', 'a', 'bad', 'dream', '.'], ['but', 'the', 'victory', 'tour', 'makes', 'that', 'impossible', '.'], ['strategically', 'placed', 'almost', 'midway', 'between', 'the', 'annual', 'games', ',', 'it', 'is', 'the', 'capitol', \"'s\", 'way', 'of', 'keeping', 'the', 'horror', 'fresh', 'and', 'immediate', '.'], ['not', 'only', 'are', 'we', 'in', 'the', 'districts', 'forced', 'to', 'remember', 'the', 'iron', 'grip', 'of', 'the', 'capitol', \"'s\", 'power', 'each', 'year', ',', 'we', 'are', 'forced', 'to', 'celebrate', 'it', '.'], ['and', 'this', 'year', ',', 'i', 'am', 'one', 'of', 'the', '3', '|', 'p', 'a', 'g', 'e', 'catching', 'fire', '-', 'suzanne', 'collins', 'stars', 'of', 'the', 'show', '.'], ['i', 'will', 'have', 'to', 'travel', 'from', 'district', 'to', 'district', ',', 'to', 'stand', 'before', 'the', 'cheering', 'crowds', 'who', 'secretly', 'loathe', 'me', ',', 'to', 'look', 'down', 'into', 'the', 'faces', 'of', 'the', 'families', 'whose', 'children', 'i', 'have', 'killed', '...'], ['the', 'sun', 'persists', 'in', 'rising', ',', 'so', 'i', 'make', 'myself', 'stand', '.'], ['all', 'my', 'joints', 'complain', 'and', 'my', 'left', 'leg', 'has', 'been', 'asleep', 'for', 'so', 'long', 'that', 'it', 'takes', 'several', 'minutes', 'of', 'pacing', 'to', 'bring', 'the', 'feeling', 'back', 'into', 'it', '.'], ['i', \"'ve\", 'been', 'in', 'the', 'woods', 'three', 'hours', ',', 'but', 'as', 'i', \"'ve\", 'made', 'no', 'real', 'attempt', 'at', 'hunting', ',', 'i', 'have', 'nothing', 'to', 'show', 'for', 'it', '.'], ['it', 'does', \"n't\", 'matter', 'for', 'my', 'mother', 'and', 'little', 'sister', ',', 'prim', ',', 'anymore', '.'], ['they', 'can', 'afford', 'to', 'buy', 'butcher', 'meat', 'in', 'town', ',', 'although', 'none', 'of', 'us', 'likes', 'it', 'any', 'better', 'than', 'fresh', 'game', '.'], ['but', 'my', 'best', 'friend', ',', 'gale', 'hawthorne', ',', 'and', 'his', 'family', 'will', 'be', 'depending', 'on', 'today', \"'s\", 'haul', 'and', 'i', 'ca', \"n't\", 'let', 'them', 'down', '.'], ['i', 'start', 'the', 'hour-and-a-half', 'trek', 'it', 'will', 'take', 'to', 'cover', 'our', 'snare', 'line', '.'], ['back', 'when', 'we', 'were', 'in', 'school', ',', 'we', 'had', 'time', 'in', 'the', 'afternoons', 'to', 'check', 'the', 'line', 'and', 'hunt', 'and', 'gather', 'and', 'still', 'get', 'back', 'to', 'trade', 'in', 'town', '.'], ['but', 'now', 'that', 'gale', 'has', 'gone', 'to', 'work', 'in', 'the', 'coal', 'mines', '—', 'and', 'i', 'have', 'nothing', 'to', 'do', 'all', 'day', '—', 'i', \"'ve\", 'taken', 'over', 'the', 'job', '.'], ['by', 'this', 'time', 'gale', 'will', 'have', 'clocked', 'in', 'at', 'the', 'mines', ',', 'taken', 'the', 'stomach-churning', 'elevator', 'ride', 'into', 'the', 'depths', 'of', 'the', 'earth', ',', 'and', 'be', 'pounding', 'away', 'at', 'a', 'coal', 'seam', '.'], ['i', 'know', 'what', 'it', \"'s\", 'like', 'down', 'there', '.'], ['every', 'year', 'in', 'school', ',', 'as', 'part', 'of', 'our', 'training', ',', 'my', 'class', 'had', 'to', 'tour', 'the', 'mines', '.'], ['when', 'i', 'was', 'little', ',', 'it', 'was', 'just', 'unpleasant', '.'], ['the', 'claustrophobic', 'tunnels', ',', 'foul', 'air', ',', 'suffocating', 'darkness', 'on', 'all', 'sides', '.'], ['but', 'after', 'my', 'father', 'and', 'several', 'other', 'miners', 'were', 'killed', 'in', 'an', 'explosion', ',', 'i', 'could', 'barely', 'force', 'myself', 'onto', 'the', 'elevator', '.'], ['the', 'annual', 'trip', 'became', 'an', 'enormous', 'source', 'of', 'anxiety', '.'], ['twice', 'i', 'made', 'myself', 'so', 'sick', 'in', 'anticipation', 'of', 'it', 'that', 'my', 'mother', 'kept', 'me', 'home', 'because', 'she', 'thought', 'i', 'had', 'contracted', 'the', 'flu', '.'], ['4', '|', 'p', 'a', 'g', 'e', 'catching', 'fire', '-', 'suzanne', 'collins', 'i', 'think', 'of', 'gale', ',', 'who', 'is', 'only', 'really', 'alive', 'in', 'the', 'woods', ',', 'with', 'its', 'fresh', 'air', 'and', 'sunlight', 'and', 'clean', ',', 'flowing', 'water', '.'], ['i', 'do', \"n't\", 'know', 'how', 'he', 'stands', 'it', '.'], ['well', '...', 'yes', ',', 'i', 'do', '.'], ['he', 'stands', 'it', 'because', 'it', \"'s\", 'the', 'way', 'to', 'feed', 'his', 'mother', 'and', 'two', 'younger', 'brothers', 'and', 'sister', '.'], ['and', 'here', 'i', 'am', 'with', 'buckets', 'of', 'money', ',', 'far', 'more', 'than', 'enough', 'to', 'feed', 'both', 'our', 'families', 'now', ',', 'and', 'he', 'wo', \"n't\", 'take', 'a', 'single', 'coin', '.'], ['it', \"'s\", 'even', 'hard', 'for', 'him', 'to', 'let', 'me', 'bring', 'in', 'meat', ',', 'although', 'he', \"'d\", 'surely', 'have', 'kept', 'my', 'mother', 'and', 'prim', 'supplied', 'if', 'i', \"'d\", 'been', 'killed', 'in', 'the', 'games', '.'], ['i', 'tell', 'him', 'he', \"'s\", 'doing', 'me', 'a', 'favor', ',', 'that', 'it', 'drives', 'me', 'nuts', 'to', 'sit', 'around', 'all', 'day', '.'], ['even', 'so', ',', 'i', 'never', 'drop', 'off', 'the', 'game', 'while', 'he', \"'s\", 'at', 'home', '.'], ['which', 'is', 'easy', 'since', 'he', 'works', 'twelve', 'hours', 'a', 'day', '.'], ['the', 'only', 'time', 'i', 'really', 'get', 'to', 'see', 'gale', 'now', 'is', 'on', 'sundays', ',', 'when', 'we', 'meet', 'up', 'in', 'the', 'woods', 'to', 'hunt', 'together', '.'], ['it', \"'s\", 'still', 'the', 'best', 'day', 'of', 'the', 'week', ',', 'but', 'it', \"'s\", 'not', 'like', 'it', 'used', 'to', 'be', 'before', ',', 'when', 'we', 'could', 'tell', 'each', 'other', 'anything', '.']]\n"
     ]
    }
   ],
   "source": [
    "# this is simplified for demonstration\n",
    "def sample_clean_text(text: str):\n",
    "    # step 1: tokenize the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # step 2: tokenize each sentence into words\n",
    "    tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # step 3: convert each word to lowercase\n",
    "    tokenized_text = [[word.lower() for word in sent] for sent in tokenized_sentences]\n",
    "    \n",
    "    # return your tokens\n",
    "    return tokenized_text\n",
    "\n",
    "# call the function\n",
    "tokens = sample_clean_text(text = file)\n",
    "\n",
    "# check\n",
    "print(tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0d76ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09997083,  0.30119884, -1.4397787 ,  0.5046606 , -0.34343073,\n",
       "       -0.7833592 ,  1.2688197 ,  0.5260871 , -0.59511495, -0.176644  ,\n",
       "        0.7458328 , -1.3920504 ,  0.15889385,  0.66812867, -0.13764444,\n",
       "        0.44899744,  1.3493843 , -0.45474172, -0.5528562 , -0.7255716 ,\n",
       "        0.4605737 , -0.14189498, -0.29231742,  0.18680154,  0.45095637,\n",
       "        0.13161023, -0.02826349,  0.64962876, -0.32305825,  0.8368614 ,\n",
       "        0.52693737,  0.30493975, -0.17283049, -0.08227683, -0.7482516 ,\n",
       "       -0.02897063,  1.0450089 ,  0.8271357 ,  0.07237857,  0.10415583,\n",
       "        0.0667223 ,  0.4342412 ,  0.41180658, -0.02637771,  0.23149379,\n",
       "        0.76170766, -0.10486843, -0.5383691 , -0.7441835 ,  0.8170352 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(tokens,vector_size=50)\n",
    "model.wv[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22431ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df90eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
